- Team: Nicolás Muñoz

- Topic: NYC AirBnB data exploration to build a machine learning model.

- Business case:

Objective: Use the Airbnb dataset to predict rental prices and identify factors influencing prices. Explore host characteristics, geographical features, and market trends to understand princing dynamics. 

Goal: Predict the price of Airbnb listings based on its features and provide actionable insights for hosts or investors to optimize their listings. 

- Data Information:

Data sources: kaggle.com, insideairbnb.com.

This dataset describes the listing activity and metrics in NYC for 2019 and includes all requiered information to find out more about hosts, geographical availability, necessary metrics to work on predictions and draw data-driven conclusiones. It contains 48895 rows and 16 columns. 


----> Plan for the next 10 days

- Day 1: Define Projects's Topic, Project Business Case, Project Objective and Initial Dataset exploration.  


- Day 2: Data Wrangling and Cleaning

Cleaning: Address missing values: Explain or drop where necessary. Convert, Tranform, Group data types as needed for analysis.

Wrangling: Remove duplicates and irrelevant features. Correct any inconsistencies within the data, such as misaligned columns or incorrect entries.

(Deliverable: Clean dataset ready for analysis)


- Day 3: Exploratory Data Analysis (EDA)

Descriptive Statistics: Use descriptive statistics to understand distributions, outliers, and key statistics.

Visual Analysis: Create visualizations (histograms, scatter plots, box plots) to identify patterns, trends, and correlations among features.

(Deliverable: EDA report with significant findings and potential features of interest)


- Day 4: Feature Engineering and Selection

Feature Engineering: Create new features from the existing dataset if needed, such as aggregated metrics or normalized features.

Feature Selection: Use correlation matrices or machine learning techniques to select the most impactful features for modeling.

(Deliverable: Refined feature set for modeling)

- Day 5: Preprocessing and Normalization 

Normalization: Normalize/standardize features to prepare them for training.

Encoding: Convert categorical data into dummy variables if necessary.

(Deliverable: Preprocessed data ready for models)

- Day 6: Model Selection and Training (Deliverable: Set of trained models with initial performance metrics)

Baseline Model: Start with a baseline model (e.g., Linear Regression or Decision Tree) to understand performance.

Advanced Models: Train multiple models, such as Random Forest, AdaBoost for better accuracy.

(Deliverable: Set of trained models with initial performance metrics)

- Day 7: Model Evaluation and Tuning 

Model Evaluation: Use cross-validation to evaluate model robustness.

Tuning and Enhancement: Tune hyperparameters for best-performing models and perform oversampling if necessary to address imbalanced datasets.

(Deliverable: Finalized model with evaluation metrics (accuracy, precision, recall, F1)

- Day 8: Visualization and Presentation 

Result Visualization: Plot prediction results and key metrics.
Insight Reporting: Summarize insights, predicted trends, and actionable recommendations generated from the model.
Documentation: Compile comprehensive project documentation covering objectives, methods, analysis, results, and conclusions.

(Deliverable: Final report and presentation of model insights and findings)


link for presentation: https://tinyurl.com/2p9mmc54
